{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
     },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjX-JAMbYya5",
        "outputId": "c54a4382-4ff0-497c-94e4-b2e4cbf22f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.29.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers transformers accelerate torch torchvision torchaudio gradio openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "login(userdata.get('Comic'))\n"
      ],
      "metadata": {
        "id": "SrwT1dgKdcKU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from getpass import getpass\n",
        "\n",
        "# Manually enter your Hugging Face token\n",
        "hf_token = getpass(\"Enter your Hugging Face token: \")\n",
        "\n",
        "model_id = \"google/gemma-2-2b-it\"\n",
        "\n",
        "# Load the tokenizer and model with authentication\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", use_auth_token=hf_token)\n",
        "\n",
        "# Create text generator pipeline\n",
        "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Generate comic script\n",
        "prompt = \"Write a short comic script about a superhero dog.\"\n",
        "response = text_generator(prompt, max_length=200)\n",
        "print(response[0][\"generated_text\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822,
          "referenced_widgets": [
            "35801e8170f64eef8abe2d8faca70c7b",
            "15030d190bb64c8c8542a5a0be673f9b",
            "c246d200e1294c9fa61cf9e155a13404",
            "1417fc74f7e04ad0a7e129929a59e972",
            "618b5ccfce1e436f89dfe6b04ed4a7f2",
            "308b86115d9944bba7cf2dd4ac19dfcd",
            "569df85fa48741ff8d5a9001c0a042b3",
            "04fc2c8e1cc840598bd0f9ee0ad839e2",
            "97af6a2356634e898ba99756d4882a81",
            "30de178edc83477eae759be28648ecc0",
            "e97126721f254b10a3e8114f35bf0b06",
            "13c08feac8bd490d8e80cf6cf8927df8",
            "90b0d710fb9c480db0a988399f42912c",
            "24d0edc3b9bc4c0686ab2933f7c9cd1d",
            "3e4ac6f81b494474af02b0e81e463155",
            "3508e87ecc564cb7bd1ac508f9c6a554",
            "5cfebb3717b6437080cb1bbbe807cdd9",
            "d1c2944d32cc4361be310bc533f499a6",
            "4c6a427fb21e40ffb51691e572b14d78",
            "9c9003048c424e98856e82a08fee5e2e",
            "49fb658fc7dd43f2b016ccaec62f6310",
            "04adfe217ba34984adc2977eaeec77b9",
            "0925387a3c2b402fad3bfdb6c6e5ef6c",
            "39396cafc1874740b2d2057fe5de72ce",
            "48eba8edd8ed4b12a1dda9d75195a3c7",
            "04b7129a22d5460c8b5fe1b305ff7ee6",
            "31c322c233d743a5b10f72a82fcb88c4",
            "f63837909968451badbdf98d4aec5b77",
            "094954d3e6a141eda67b34e65baae1e9",
            "9166cd83adc14bd3bc95a615fb10bece",
            "3eae3639299d44869d7f675d12a1d7a8",
            "f7efd8c1e56649b7b9b8bb8b12e4e38a",
            "6984a89adf9d48a59b9760e77de61490",
            "6789153f34964dceb118e64cb42903df",
            "11c104d844094e028ba12ba3a913b881",
            "df8eb4d592b84b12952ff5780e384bbb",
            "29eb8689a04f4ad697ec6faa8ef37323",
            "e5686ca6fbdb469aa8a6b6ef325ac31a",
            "0cd79dcce667480eb8788656df12599c",
            "d5d5f976f71d448c9b19bbab0e229a91",
            "7fd3f0a16f8142289046a2d71a19e3db",
            "00113af7ea0f4894a9952cdfbdabf0a2",
            "519afbb770c5498eab11ac68b24f9da0",
            "51a60c50ff7b43c6a4b00478e5aa512e",
            "217a777d0a9c497c85faf5d077400977",
            "b20ccc5e3b29481f85cea1dfbdc4bf16",
            "fc2abbb293994dbe9ecab9174905a9c6",
            "b2881308bcbe48f7bbfc68cbe6de5ea4",
            "6fd99b46bcad49f4aecd615d704862fb",
            "21d4eb14b4474677b615c2b59c54a9c8",
            "ab398e1137494bbba6c122eae2244e1c",
            "7c3da77234474631828fc8cce85042f7",
            "abb412831eb5429f8502332fcc90d6ca",
            "b408c09437bf4c8593a64d2d07f9af96",
            "276bdc6f1d7a464185dd1380b6bc2f9a",
            "00b9126cae33449f9dce94e803798765",
            "fe81dcc0a8734e7b9dbb713094ea18d1",
            "302866fba564413e8ab265b3bf095efb",
            "fb93767478cb45ee8ac4c33036a0632d",
            "60d62e1213d043f9b176cadb4feed15a",
            "dfe2a173402247b1ae67b40caad107f5",
            "ab7b23fda9a84e4eb5a113ce3061bc21",
            "9abd3c096e4f408cba8b4189d9aefb48",
            "b68175bf9cd74b4f8d1636d591961b57",
            "990f0d601b0647cc8d971776c8e52b7a",
            "e736276c53754aa5a01852d81a8608c3",
            "0200551f7ea841b1b511cd951909175f",
            "ce10322ce38a48c68da076052dc92d9c",
            "440e25b7bb5a486dae6e8ce709ad53f0",
            "4a4614d6708a41bab47ab9d414f1f9b1",
            "caf64154cc8240baa8e07006f8127d1a",
            "e644f058f37b499599d2af2cc3697463",
            "2e322d43387145cb97ef3bdb2712ff84",
            "c2a1ff0cf4b44a17bd05efc754f4355e",
            "a43ca59dde8e4ba8bacdf2cd178909d3",
            "86fa10e26f134776aeb02f11541603a1",
            "c107cf5e38714b3990c1ee4e76edfad8",
            "c1d9b5badf354b59a670a6983d39357c",
            "6f3e450e743847a2a5f9ae212490d341",
            "3d01376d562940a2b6017c364e3f2017",
            "93f89f0dc5d644259d8c123522310726",
            "e813d61de8be4e58a9eee88c05fec159",
            "c39872136dd843b1ac6ed82f289de532",
            "dd3180bd11044872838cdf3989fe7240",
            "676a852209a44b6dba1ee52c0fb6d09c",
            "edbda6fc60e24eac8ab3fec4ff20a452",
            "f422abea76d549d98999a40a027f637e",
            "f8c01201ea35478bab6fcc6850159886",
            "a9c8ed7ef02440bba5df5467f6f06740",
            "d60a931d80fa441eaa4798d2c5f9f89b",
            "472b374d6a3740c0aca9992ce8639d23",
            "fce5241a5db148c68e2cdd46b8923d45",
            "6956deb160da4e41b2a79e48c22bff25",
            "fb7fb6e8dd264ccea65bd6e0a8420499",
            "a597442093f84fb48e42ec58ca65bd1f",
            "209a007a1c4148b4b6dd87bd3c76c20d",
            "bd206a8ffe6c4acd9b7e62ac6d8fd780",
            "fb914318260645ecaba35456e4a96a5b",
            "6270eee0d0674a7ca75750a5bf5389cd",
            "769d3ec6d02c4a6791b89b38aac4ed2f",
            "1cb039a75fe049308ce83c2efcb6f799",
            "d7fcdd3993a04dbea1fc0524c6f4a772",
            "0ff2ec78504b4b89a4272ef84e9001e4",
            "292a4033986e4308bebca633be612bf8",
            "a5efdb87f5c84107bc01d41b1998fd9e",
            "17d3d0ab10364fa892ea51c05c8c77ed",
            "ef7eab2ec299491692aef0a78a8de30b",
            "255ea6b028b646ae83a124d38f2b5da7",
            "5a897c942e1b45c69f7fdcbd69b9ac31",
            "cbfbaeafcf7c401c852750558353dfab",
            "ef94cf3dd3d043279333c8c135cdb8be",
            "11ae67e52b3c4a8e9afff0c848a5e3ee",
            "7898623dbd674dbbba2cbd8840b53ef3",
            "f177d7d6b55a42f49e34acad99490289",
            "6a164d8107cc4cef8345f27b3dccafa1",
            "875f0608e4e64b5095e07b0ad25367ad",
            "0d914d1e7a00409bb8d39b8ba12f0c78",
            "0a91e2d0e68b457caaec6e66dfef23da",
            "a0b2f704f3ac480ebfeb157dbc47541b",
            "d8cc2dbba75f4e90825054997836f453",
            "b66340f1e6ef4fff9f81d026dc324309"
          ]
        },
        "id": "3P8C0whSjZkr",
        "outputId": "4d92acf2-af01-4341-f17c-85867b5b7a7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:862: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35801e8170f64eef8abe2d8faca70c7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13c08feac8bd490d8e80cf6cf8927df8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0925387a3c2b402fad3bfdb6c6e5ef6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6789153f34964dceb118e64cb42903df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "217a777d0a9c497c85faf5d077400977"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00b9126cae33449f9dce94e803798765"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0200551f7ea841b1b511cd951909175f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d9b5badf354b59a670a6983d39357c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9c8ed7ef02440bba5df5467f6f06740"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "769d3ec6d02c4a6791b89b38aac4ed2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef94cf3dd3d043279333c8c135cdb8be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a short comic script about a superhero dog.\n",
            "\n",
            "**Panel 1:**\n",
            "\n",
            "* **Setting:** A bustling city street. Cars honk, people rush by, pigeons squawk.\n",
            "* **Characters:** A scruffy terrier mix, wearing a red cape and a tiny mask, leaps onto a fire escape. He's panting, clearly exhausted.\n",
            "* **Caption:** \"Sparky was tired. He'd been chasing a runaway hotdog cart for hours.\"\n",
            "\n",
            "**Panel 2:**\n",
            "\n",
            "* **Setting:** The same fire escape, Sparky is now perched on a ledge, looking down at the street.\n",
            "* **Characters:** Sparky, with a determined expression, looks at a group of pigeons huddled together.\n",
            "* **Caption:** \"But Sparky knew his duty. He had to stop the pigeons from stealing the city's last hotdog.\"\n",
            "\n",
            "**Panel 3:**\n",
            "\n",
            "* **Setting:** A close-up of Sparky's eyes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Load a comic-style model (change if needed)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"ogkalu/Comic-Diffusion\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "def generate_comic_panel(description, text):\n",
        "    \"\"\"Generates a comic-style image and overlays English text on it.\"\"\"\n",
        "    image = pipe(description).images[0]\n",
        "\n",
        "    # Add text to the image\n",
        "    image = add_text_to_image(image, text)\n",
        "\n",
        "    return image\n",
        "\n",
        "def add_text_to_image(image, text):\n",
        "    \"\"\"Overlays English text onto the generated comic panel.\"\"\"\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()  # Uses default font; replace with TTF for better quality\n",
        "\n",
        "    # Position text at the top\n",
        "    draw.text((20, 20), text, fill=\"black\", font=font)\n",
        "\n",
        "    return image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794,
          "referenced_widgets": [
            "54e701e4ad9847b4a575be248baec78b",
            "77e6bf9f796c4f4aa8e3eb647be82cb4",
            "9437402a096d4f908d0d28770e5627ea",
            "9a2a0a9dc92b40cb95ce2e453c5265ca",
            "2ae854df34a647219e4e9b2315ee69b7",
            "e67bc77e187348aaaec1eaf60050d4a1",
            "a95c1f589b5e4499ac62b08f5793c8af",
            "02547374eac6437bbd4f72a10bbacba8",
            "d3d4b4e61a85421c8a7d9660bccb4f5f",
            "c6024221ae084d60a628d9333f300041",
            "bc59cc5376a24f2fa20a4795d7db3bbd",
            "2a7ba852a0fd4a159765d6c062d70242",
            "27cbd4f217314db1a182d5fde0c31bb7",
            "c5e5c240c730478990a18bbe25508a9f",
            "80e24714d76644efa2d5ae9593074334",
            "c7ea4f3dd07e4c53b2d37ba15af2648d",
            "984f899b1d3a44ecacb6fe939ee6fc32",
            "d38ab1b93eff48a19d18c4405c94b741",
            "59b82b26db8f4e9b87395f3e2dec162c",
            "90bae6dcb10e4a35a0f7fb46305590d5",
            "a0b1c9dc57e34c01a1b17944b41aefdf",
            "17aa4bf7b9fc4a06be978e627e6bc2d1",
            "f19edd075cda41c0960d2854f3dfca2a",
            "b351801bbf164ba0bf984d46709f0ea1",
            "3859db9b85904fc8b008951c5f13b9c6",
            "4a6a654a987c4d468c2bfbba37366d29",
            "4086913325bd4cf2b1bf8353048f300c",
            "5b8205ac3e6742b49d353cc35ac63da0",
            "e98f387357e645b28a4e1afed4828bc3",
            "db43c4fdf90e40468b49233283ddad2d",
            "c42ae9eee51a405c9fed8b9eabedcf19",
            "d2da5865a5254229accb650fa85f3514",
            "a3b123cc0a2a430393d93429a0f03b22",
            "051ccdb661f7446086639f97e75a90da",
            "65b063c4d68b4da6b9b1d78bde78177e",
            "074b7a5607c3427ab121a5f8e52c2771",
            "f9e16391c0fa4599bee0149c1566918b",
            "f2eb189823e2461d82f4b5ce1aab14ef",
            "7d32f02a97ad4762a513b665a25277b4",
            "fe63da3689674adbb47560a7886cd934",
            "f10edf55345d461a8c3a8bdf187d86bf",
            "537c734da70949889d77cc8fec75802d",
            "ccc1051ec35d496596c98f4bd7631d70",
            "fde5da467ef1455c94e5b24bc771184f",
            "c31cb5526c684b3d8283685f87831782",
            "aacd607d066f4e8795dc3e4da1462ae0",
            "c816a315f2d24e1fbb76a77d45b54487",
            "8801c82a3f7243b5a8654da90af57b9c",
            "d4cfea8367ce4136b90ef1bfee3f8738",
            "8dbfe506498f49e6b68e375af1a84ba5",
            "51c266b5e1644d2887f83caec4bce040",
            "76056d97ff4b4ecea129421701f264ad",
            "ade60bbc51664b8ca0a0477891a848e3",
            "dac4c87b17204dbeaf7617a1d97f97c8",
            "4b9a5e7f50724a56b899ea5e2a9fea21",
            "e66f0ccdfa4644b2b4f90631090e4140",
            "6c9ecc53fa1944f9877844659b4bc4c7",
            "d529e03634924879a4d7f88e24f9c1f5",
            "7cf1416c171a4075acd85a52c113c4d6",
            "5b38d7985b7446a0835d4676a83ed6ab",
            "c759f54b51f940a3b18b1d14976514ab",
            "9959ba48c8c248c3b98ac3a549e5ed1a",
            "6dfbff9647f2450d8e4fee3cf182453d",
            "f06e61c37fae47fd90e0896ac40af98f",
            "74321cc11fed4ca0add23be745786b50",
            "f94219f11d974a1191e10a806d08f350",
            "d7d5f6dd8e2e4fabbb4cc187cec7cdbd",
            "cf5c8823922249d99be2a1173d1e8368",
            "1e04c7cf92a741d2bc40cebded6b852a",
            "7a2ee26a535547a29dd0f4c5d3b97717",
            "dacfae8d56b3430b8abf1d61d17be35a",
            "7076d8e62b53461fa324a6d8cc7fa0cd",
            "642d46dabed1497797ba3a152973bc15",
            "23dc61a0ebbe4c41a6bd1ac3ce5052f2",
            "c6f3f119cb754cce85a4fd5ee0fcdaec",
            "7652b7cd348e486fb42ebda8c41fb20e",
            "d7b592cbf7784604b243cd9acdf7d611",
            "b5e6e5470c404b538c3245c29144699c",
            "983a8c2ec56b422e92851f0bd0553a72",
            "d7e0b961f39e43d8a496e847261bef07",
            "87a3f8f6168e43088944f48e00a218b1",
            "15df0987af2f4affb7625517c11f0e3e",
            "417da7cfccd246a08ffa66dc36d10543",
            "9368809fe0474e1eaf2fffa60ddd3289",
            "08ab607b6d1243babe09c0687407a22d",
            "5d25b4c5a5a644b3b9fc9cfdb474693f",
            "33490e5c7d76400c8302fd303cbbd68a",
            "403d73c5c02f477aab88d1cc1ff3cd93",
            "34e275908ef5494f91f9d1b98dfc52cd",
            "44f2439f472445bbbd0a2cb3af44e25c",
            "8f91851d5f704dd39c00a91b318d30a4",
            "b0e10c8399e04039bfcde3bc07b3e83d",
            "634fb744256c408baa8a2b69dcfa9871",
            "ca3d12bba53742a8b59c8e8a3fbf8b18",
            "5e6c0fdef3ba4c4e929693a201546807",
            "2c4fb0717d6e4307931cce6c4a40f8ee",
            "6fb7d1560d294f68bae883e24f971bd7",
            "c6039587875e440a95240d2b89fe463d",
            "449c1ea6c2c2452199d9bb2ceda70a0b",
            "57e2663dceb943b0a83b0dc340b808e6",
            "f0df65613e3947c1a641e770809a6d19",
            "b9354118782f40fa99f07b4d36aa4ce3",
            "b7f0947e7e2e4bc98e6e18914b9a7e90",
            "8e0ab12a504743d38d575ff8ebd18887",
            "6fd2fc29807a44a7aee1c8a6a97dd9a3",
            "b4d37b4ef0bd41afb7a3742091c27709",
            "9dde0b7be7f4480a8d845ea3e1d1fced",
            "25a64090e76d45249f932dcdd7448845",
            "9ca3414a4d4341b796284cb6cdbf3017",
            "d17383c03293421aac4ac765abadb79f",
            "34ecb7ade0144297ac60bf00ad7b9048",
            "86de2f657c49458dae557ffd09f45ce5",
            "483eb310e8c54a599cc532e475f2b5ac",
            "b474841b04684be886407f09e626547a",
            "c80c46e0b4eb43f885572afbffdfe379",
            "111c6243e6e546c88349d46caf122765",
            "ec48d5a325354b3aacc82aa5172960ec",
            "f1340a60449841ed967ff0389948cfda",
            "8a70e274f2104231a1ca4c654f4751d0",
            "3727c6c9b5f34ddabaeea5d3aa57e0b4",
            "e0cc2ccc98414c819fdda99edf5391a6",
            "3b5a800962714a698540342104333d02",
            "95f09cea07c74ff89929a8684346eb8d",
            "c2aedcd351194c4fa0814cc90e7aa768",
            "8e30c4cfa9b340f2b7c3349ffe1e5075",
            "35fd93e446ee45c4bb9efd436d9d94c6",
            "482d0ca540144fa0a76c59ed5c92654d",
            "101435789e0b4297996549d4d34703b8",
            "edf271862fb24ed6867d1827928c1a2f",
            "079e5756beda4d6898f1b67a4ee1731e",
            "bcff3e7145584b469d7e242041ade8ab",
            "7f94310d04dd4b29a95f558d0b21e710",
            "a15e6c523b994b8f9e140214b5081c56",
            "599d082960694741a54cf7353175260a",
            "170569feee354da6a50ac3f19cfead4e",
            "740fde7c498d428b98373682670a2135",
            "083f6a232ec540569b5791a41004b068",
            "be891de0810f4a4b8b6dc37f81b59f25",
            "d45411ac0f7f418f9f06ea88b78c18ce",
            "a892c1c5c8ed4254ade226c1b273f949",
            "7838297819b045998117c2c574ee7ca0",
            "453c42aca376494da63b906486046ef9",
            "acfd3b482de84bb18f47990c4afea45d",
            "2c8d489e8d4d42d58ab2a12da8cf2bcc",
            "03e38b36e74f42188add48a50fe08c85",
            "40b947b718cb4f37b9df867395933294",
            "5f1e078332674bc09c83bdc2a384ea39",
            "6f2877e030604e129e18995484870d46",
            "ca8a3e4cf6f4434fb652321d61444626",
            "acceba324b444acfa2ebed71a22bb8a7",
            "068fa1c35b2c4c0f9dfd71e1a71c5afa",
            "469891fdc6534c82ada095afd06a26ae",
            "3b0e526bb4cd42f8b775551c0b5dc0e3",
            "3fad4ce6ba374c2aa9c2fa5180c0332e",
            "e54a03aa735c49b39b665963656a7361",
            "4676ce0220ec46f9bfda955e79511b7e",
            "cee2e9c06ca64b549f89464f2d1b30c8",
            "bc82c6efcb904a47a741f7f004e28dd6",
            "592c427afee143e6a30d3f3a64b06c55",
            "01a3b3ee1f744e6eaeac1ff52b519272",
            "5b8cc22835d947278d1573915c815594",
            "6131a6347c3545aaa2e1338047b3c82b",
            "f63c6874ae8b443299fa16d2f355f112",
            "d6027f6eea4e4b3fad38e941cfed11ad",
            "a17e7083fd864257a0ff1338c4def4d6",
            "7bdc8c5843684d3ea2d852587e3a5b66",
            "afd583292eca4e1db95e9b5a70f42508",
            "c352f5dfcc7245b1af6920a690f84387",
            "ff5c038251c74268a83171638fde381e",
            "796a46b9b06a404dbf8260e16ca7c4fe",
            "989c0710235944bfb6cb163c4f6ebebe",
            "ba96d12ab0164cc3b950769a95f7f990",
            "9b8ba7e1c308489b896b25a0261366cb",
            "af1f9d8714ec4ba1aeea12400ba15a04",
            "86a33eaf9dae4caca57805f90eef1e0d",
            "ab61cda72fcf4163bd81076724c9c92d",
            "375cb12735644f4fb9f450f4d33e36a9",
            "c3e2bf1c566c46e2923db9490c66e045",
            "c6e17fdd853947ba96a28eb88e3901ad",
            "18f48e1515e34debbf1a4a8d71f029e3",
            "b04bea7d53534a94902e0bdea14df324",
            "625f64bea9ec48df8e3d96bc4d359b38",
            "e87add373e274c6e9d5a2d5e5382dc38",
            "10e6b99c1a874214ad110d28bc6cf277",
            "cc526a890bad43d5b3e3fef10565b8a3",
            "58a04e6002d8422a8bceb6ee9adff86d",
            "22e27e189ca54ce2a74fc3e5c327d1a2",
            "d8d72c16dc3d4c40b52d403fc24685a7",
            "78b29861f9b742aeaa018214abf76cdb",
            "03e048d25043443b8f4ca44f0852a83a",
            "1f38a32c926440daa623c8defee12fde",
            "16b2dd728a1c40a181ebc36b9c0d958d",
            "51cb7ff35ec443179c3612dfb860052e",
            "084755b11b234bfc99a429dc56a32c3b",
            "9ff43183455042538e4fcd557fe159b2",
            "185427554db141f49f473b8703e59004",
            "0a2143a17396467992675aea9eaf626b",
            "38434117adeb48c2a9176e0a28964ac9"
          ]
        },
        "id": "T5pBpV1PuWX8",
        "outputId": "ac09fd79-7096-4679-c67a-e52ce8659313"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_index.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54e701e4ad9847b4a575be248baec78b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7ba852a0fd4a159765d6c062d70242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f19edd075cda41c0960d2854f3dfca2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051ccdb661f7446086639f97e75a90da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c31cb5526c684b3d8283685f87831782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e66f0ccdfa4644b2b4f90631090e4140"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7d5f6dd8e2e4fabbb4cc187cec7cdbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.84k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5e6e5470c404b538c3245c29144699c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)omic-Diffusion%20%C2%B7%20Hugging%20Face:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34e275908ef5494f91f9d1b98dfc52cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57e2663dceb943b0a83b0dc340b808e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34ecb7ade0144297ac60bf00ad7b9048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b5a800962714a698540342104333d02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/748 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a15e6c523b994b8f9e140214b5081c56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c8d489e8d4d42d58ab2a12da8cf2bcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e54a03aa735c49b39b665963656a7361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/581 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bdc8c5843684d3ea2d852587e3a5b66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "375cb12735644f4fb9f450f4d33e36a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8d72c16dc3d4c40b52d403fc24685a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--ogkalu--Comic-Diffusion/snapshots/ff684f581ab24e094e2055d9422e9ee076d139a8/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--ogkalu--Comic-Diffusion/snapshots/ff684f581ab24e094e2055d9422e9ee076d139a8/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--ogkalu--Comic-Diffusion/snapshots/ff684f581ab24e094e2055d9422e9ee076d139a8/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--ogkalu--Comic-Diffusion/snapshots/ff684f581ab24e094e2055d9422e9ee076d139a8/unet.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def generate_comic(prompt):\n",
        "    \"\"\"Generate a comic script and corresponding images.\"\"\"\n",
        "    script_response = text_generator(prompt, max_length=200, do_sample=True)\n",
        "    script = script_response[0][\"generated_text\"]\n",
        "\n",
        "    # Split into 3 panels (each a short sentence)\n",
        "    panels = script.split(\". \")[:3]\n",
        "    if len(panels) < 3:\n",
        "        panels += [\"(No more content)\"] * (3 - len(panels))\n",
        "\n",
        "    images = [generate_comic_panel(panel, panel) for panel in panels]\n",
        "\n",
        "    return [script] + images\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🖼️ ComicCrafter AI - Generate Comics from Prompts\")\n",
        "\n",
        "    prompt = gr.Textbox(label=\"Enter your prompt\", placeholder=\"A superhero cat saving the city...\")\n",
        "    output_text = gr.Textbox(label=\"Generated Comic Script\")\n",
        "    output_images = [gr.Image(label=f\"Panel {i+1}\") for i in range(3)]\n",
        "\n",
        "    btn = gr.Button(\"Generate Comic\")\n",
        "    btn.click(generate_comic, inputs=prompt, outputs=[output_text] + output_images)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "hIopmOQDnt0X",
        "outputId": "47398f22-605f-4e55-b9f2-9d476200c4ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2d427e5a97d5303d42.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2d427e5a97d5303d42.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
